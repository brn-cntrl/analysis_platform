{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd3a4bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:45:49.306849Z",
     "iopub.status.busy": "2025-10-15T18:45:49.306725Z",
     "iopub.status.idle": "2025-10-15T18:45:50.033176Z",
     "shell.execute_reply": "2025-10-15T18:45:50.032794Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  \n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from analysis_utils import (\n",
    "    prepare_event_markers_timestamps,\n",
    "    find_timestamp_offset,\n",
    "    extract_window_data\n",
    ")\n",
    "\n",
    "DATA_FOLDER = 'data'\n",
    "OUTPUT_FOLDER = 'data/outputs'\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "results = {\n",
    "    'status': 'processing',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'errors': [],\n",
    "    'warnings': [],\n",
    "    'markers': {},\n",
    "    'analysis': {},\n",
    "    'plots': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d62722e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:45:50.045625Z",
     "iopub.status.busy": "2025-10-15T18:45:50.045370Z",
     "iopub.status.idle": "2025-10-15T18:45:50.049392Z",
     "shell.execute_reply": "2025-10-15T18:45:50.049020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Analysis complete! Results saved to data/outputs/results.json\n",
      "Status: completed\n",
      "Plots generated: 0\n"
     ]
    }
   ],
   "source": [
    "results['status'] = 'completed' if len(results['errors']) == 0 else 'completed_with_errors'\n",
    "results_path = os.path.join(OUTPUT_FOLDER, 'results.json')\n",
    "\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Analysis complete! Results saved to {results_path}\")\n",
    "print(f\"Status: {results['status']}\")\n",
    "print(f\"Plots generated: {len(results['plots'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17c4dd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:45:50.052525Z",
     "iopub.status.busy": "2025-10-15T18:45:50.052382Z",
     "iopub.status.idle": "2025-10-15T18:45:50.181778Z",
     "shell.execute_reply": "2025-10-15T18:45:50.181451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. LOADING CONFIGURATION\n",
      "--------------------------------------------------------------------------------\n",
      "Using subject folder: G3_1.4.2_2025-05-22T204215.885316_eGFub25vdmFhcmlhQHlhaG9vLmNvbQ\n",
      "✓ Manifest loaded\n",
      "  EmotiBit files: 1\n",
      "  Event markers: Yes\n",
      "  Selected metrics: ['HR']\n",
      "  Comparison groups: 2\n",
      "\n",
      "2. LOADING EVENT MARKERS\n",
      "--------------------------------------------------------------------------------\n",
      "Loading from: data/G3_1.4.2_2025-05-22T204215.885316_eGFub25vdmFhcmlhQHlhaG9vLmNvbQ/2025-05-23_eGFub25vdmFhcmlhQHlhaG9vLmNvbQ==_event_markers.csv\n",
      "✓ Loaded 101466 rows\n",
      "  Columns: ['timestamp', 'EDA', 'HR', 'BI', 'PG', 'event_marker', 'condition']\n",
      "  ✓ Found 'timestamp' column (ISO format) - converting to unix_timestamp\n",
      "  ⚠ Dropped 607 rows with invalid timestamps\n",
      "  ✓ Converted 100859 timestamps from ISO to Unix format\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. LOADING CONFIGURATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Find the most recent subject folder\n",
    "subject_folders = []\n",
    "for item in os.listdir(DATA_FOLDER):\n",
    "    item_path = os.path.join(DATA_FOLDER, item)\n",
    "    if os.path.isdir(item_path) and item not in ['outputs', 'test_temp']:\n",
    "        manifest_path = os.path.join(item_path, 'file_manifest.json')\n",
    "        if os.path.exists(manifest_path):\n",
    "            mtime = os.path.getmtime(item_path)\n",
    "            subject_folders.append((item, item_path, mtime))\n",
    "\n",
    "if not subject_folders:\n",
    "    error_msg = \"No subject folder with manifest found\"\n",
    "    print(f\"ERROR: {error_msg}\")\n",
    "    results['errors'].append(error_msg)\n",
    "    results['status'] = 'failed'\n",
    "else:\n",
    "    # Sort by modification time and get the most recent\n",
    "    subject_folders.sort(key=lambda x: x[2], reverse=True)\n",
    "    folder_name, subject_folder, _ = subject_folders[0]\n",
    "    \n",
    "    print(f\"Using subject folder: {folder_name}\")\n",
    "\n",
    "    manifest_path = os.path.join(subject_folder, 'file_manifest.json')\n",
    "    with open(manifest_path, 'r') as f:\n",
    "        manifest = json.load(f)\n",
    "    \n",
    "    print(f\"✓ Manifest loaded\")\n",
    "    print(f\"  EmotiBit files: {len(manifest.get('emotibit_files', []))}\")\n",
    "    print(f\"  Event markers: {'Yes' if manifest.get('event_markers') else 'No'}\")\n",
    "    \n",
    "    analysis_config = manifest.get('analysis_config', {})\n",
    "    selected_metrics = analysis_config.get('selected_metrics', [])\n",
    "    comparison_groups = analysis_config.get('comparison_groups', [])\n",
    "    \n",
    "    print(f\"  Selected metrics: {selected_metrics}\")\n",
    "    print(f\"  Comparison groups: {len(comparison_groups)}\")\n",
    "    \n",
    "    if len(comparison_groups) < 2:\n",
    "        results['warnings'].append('Need at least 2 comparison groups')\n",
    "        print(\"  ⚠ Warning: Need at least 2 comparison groups\")\n",
    "\n",
    "print(\"\\n2. LOADING EVENT MARKERS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    if manifest.get('event_markers'):\n",
    "        event_markers_path = manifest['event_markers']['path']\n",
    "        print(f\"Loading from: {event_markers_path}\")\n",
    "        \n",
    "        df_markers = pd.read_csv(event_markers_path)\n",
    "        print(f\"✓ Loaded {df_markers.shape[0]} rows\")\n",
    "        print(f\"  Columns: {df_markers.columns.tolist()}\")\n",
    "        \n",
    "        df_markers = prepare_event_markers_timestamps(df_markers)\n",
    "        \n",
    "        results['markers'] = {\n",
    "            'shape': df_markers.shape,\n",
    "            'columns': list(df_markers.columns),\n",
    "            'head': df_markers.head(10).replace({np.nan: None}).to_dict('records')\n",
    "        }\n",
    "        \n",
    "        if 'condition' in df_markers.columns:\n",
    "            results['markers']['conditions'] = df_markers['condition'].value_counts().to_dict()\n",
    "        \n",
    "    else:\n",
    "        raise FileNotFoundError(\"No event markers file in manifest\")\n",
    "        \n",
    "except Exception as e:\n",
    "    error_msg = f\"Error loading event markers: {str(e)}\"\n",
    "    print(f\"ERROR: {error_msg}\")\n",
    "    results['errors'].append(error_msg)\n",
    "    df_markers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf06dd6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:45:50.183551Z",
     "iopub.status.busy": "2025-10-15T18:45:50.183417Z",
     "iopub.status.idle": "2025-10-15T18:47:33.805997Z",
     "shell.execute_reply": "2025-10-15T18:47:33.805608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. ANALYZING SELECTED METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Analyzing metric: HR\n",
      "----------------------------------------\n",
      "  Loading: 2025-05-22_20-42-36_eGFub25vdmFhcmlhQHlhaG9vLmNvbQ==_emotibit_ground_truth_HR.csv\n",
      "  ✓ Loaded 5563 rows\n",
      "  Calculating timestamp offset...\n",
      "  Event Marker Start: 2025-05-22 13:42:36.738613\n",
      "  EmotiBit Start: 2025-05-22 20:33:59.566568\n",
      "  Calculated Offset: -24682.83s (-6.86 hours)\n",
      "\n",
      "  Extracting data for 'Baseline'...\n",
      "  Found 2573 occurrences of 'biometric_baseline'\n",
      "  Extracted 142 data points across all occurrences\n",
      "\n",
      "  Extracting data for 'SART 1'...\n",
      "  Found 7578 occurrences of 'sart_1'\n",
      "  Extracted 396 data points across all occurrences\n",
      "\n",
      "  Baseline: mean=72.96, std=4.45, n=142\n",
      "\n",
      "  SART 1: mean=68.17, std=4.94, n=396\n",
      "\n",
      "  Creating visualizations...\n",
      "    ✓ Saved: HR_individual_timeseries.png\n",
      "    ✓ Saved: HR_timeseries.png\n",
      "    ✓ Saved: HR_comparison.png\n"
     ]
    }
   ],
   "source": [
    "if df_markers is not None and selected_metrics:\n",
    "    \n",
    "    print(\"\\n3. ANALYZING SELECTED METRICS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric in selected_metrics:\n",
    "        print(f\"\\nAnalyzing metric: {metric}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Find and load metric file\n",
    "            metric_file = None\n",
    "            for emotibit_file in manifest['emotibit_files']:\n",
    "                if f'_{metric}.csv' in emotibit_file['filename']:\n",
    "                    metric_file = emotibit_file['path']\n",
    "                    break\n",
    "            \n",
    "            if not metric_file:\n",
    "                print(f\"  ⚠ Warning: File for metric {metric} not found - skipping\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"  Loading: {os.path.basename(metric_file)}\")\n",
    "            df_metric = pd.read_csv(metric_file)\n",
    "            print(f\"  ✓ Loaded {df_metric.shape[0]} rows\")\n",
    "            \n",
    "            # Calculate offset\n",
    "            print(f\"  Calculating timestamp offset...\")\n",
    "            offset = find_timestamp_offset(df_markers, df_metric)\n",
    "            \n",
    "            # Extract data for each comparison group\n",
    "            group_data = {}\n",
    "            \n",
    "            for group in comparison_groups:\n",
    "                group_label = group['label']\n",
    "                print(f\"\\n  Extracting data for '{group_label}'...\")\n",
    "                \n",
    "                data = extract_window_data(df_metric, df_markers, offset, group)\n",
    "                \n",
    "                if len(data) == 0:\n",
    "                    print(f\"  ⚠ Warning: No data for group '{group_label}' - skipping\")\n",
    "                    continue\n",
    "                \n",
    "                group_data[group_label] = data\n",
    "            \n",
    "            # Calculate statistics for each group\n",
    "            if len(group_data) < 2:\n",
    "                print(f\"  ⚠ Warning: Need at least 2 groups with data - skipping {metric}\")\n",
    "                continue\n",
    "            \n",
    "            metric_col = df_metric.columns[-1]\n",
    "            metric_results = {}\n",
    "            \n",
    "            for group_label, data in group_data.items():\n",
    "                values = data[metric_col].dropna()\n",
    "                \n",
    "                stats = {\n",
    "                    'mean': float(values.mean()),\n",
    "                    'std': float(values.std()),\n",
    "                    'min': float(values.min()),\n",
    "                    'max': float(values.max()),\n",
    "                    'count': int(len(values))\n",
    "                }\n",
    "                \n",
    "                metric_results[group_label] = stats\n",
    "                print(f\"\\n  {group_label}: mean={stats['mean']:.2f}, std={stats['std']:.2f}, n={stats['count']}\")\n",
    "            \n",
    "            # Store results\n",
    "            results['analysis'][metric] = metric_results\n",
    "            \n",
    "            # ================================================================\n",
    "            # CREATE VISUALIZATIONS\n",
    "            # ================================================================\n",
    "            \n",
    "            print(f\"\\n  Creating visualizations...\")\n",
    "            \n",
    "            # Define color palette for groups (up to 10 groups)\n",
    "            colors = ['#4CAF50', '#2196F3', '#FF9800', '#9C27B0', '#F44336', \n",
    "                      '#00BCD4', '#FFEB3B', '#795548', '#607D8B', '#E91E63']\n",
    "            \n",
    "            group_labels = list(metric_results.keys())\n",
    "            \n",
    "            # Plot 1: Individual time series for each comparison group\n",
    "            num_groups = len(group_data)\n",
    "            fig, axes = plt.subplots(num_groups, 1, figsize=(14, 4 * num_groups), squeeze=False)\n",
    "\n",
    "            for idx, (group_label, data) in enumerate(group_data.items()):\n",
    "                ax = axes[idx, 0]\n",
    "                values = data[metric_col].dropna()\n",
    "                \n",
    "                # Convert to elapsed time in seconds from start of this specific event\n",
    "                timestamps = data['AdjustedTimestamp'].values\n",
    "                start_time = timestamps.min()\n",
    "                elapsed_seconds = timestamps - start_time\n",
    "                \n",
    "                color = colors[idx % len(colors)]\n",
    "                \n",
    "                # Plot line and scatter\n",
    "                ax.plot(elapsed_seconds, values, color=color, linewidth=1.5, alpha=0.8)\n",
    "                ax.scatter(elapsed_seconds, values, color=color, s=12, alpha=0.6)\n",
    "                \n",
    "                # Add mean line\n",
    "                mean_val = values.mean()\n",
    "                ax.axhline(y=mean_val, color='red', linestyle='--', alpha=0.5, \n",
    "                        label=f'Mean: {mean_val:.2f}')\n",
    "                \n",
    "                # Statistics text box\n",
    "                stats_text = f'Mean: {values.mean():.2f}\\nStd: {values.std():.2f}\\nn: {len(values)}'\n",
    "                ax.text(0.98, 0.97, stats_text, transform=ax.transAxes,\n",
    "                    verticalalignment='top', horizontalalignment='right',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                    fontsize=9, family='monospace')\n",
    "                \n",
    "                ax.set_xlabel('Elapsed Time (seconds)', fontsize=11)\n",
    "                ax.set_ylabel(f'{metric} Value', fontsize=11)\n",
    "                ax.set_title(f'{group_label}', fontsize=12, fontweight='bold', color=color)\n",
    "                ax.grid(True, alpha=0.3, linestyle='--')\n",
    "                ax.legend(loc='upper left', fontsize=9)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plot1_path = os.path.join(OUTPUT_FOLDER, f'{metric}_individual_timeseries.png')\n",
    "            plt.savefig(plot1_path, dpi=100, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            results['plots'].append({\n",
    "                'name': f'{metric} Individual Time Series',\n",
    "                'path': plot1_path,\n",
    "                'filename': f'{metric}_individual_timeseries.png',\n",
    "                'url': f'/api/plot/{metric}_individual_timeseries.png'\n",
    "            })\n",
    "            print(f\"    ✓ Saved: {metric}_individual_timeseries.png\")\n",
    "            \n",
    "            # Plot 2: Time series - chronological progression\n",
    "            fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "            # Combine all group data in chronological order with event timestamps\n",
    "            all_time_series_data = []\n",
    "\n",
    "            for group_label, data in group_data.items():\n",
    "                values = data[metric_col].dropna()\n",
    "                timestamps = data['AdjustedTimestamp'].values\n",
    "                \n",
    "                for i, (ts, val) in enumerate(zip(timestamps, values)):\n",
    "                    all_time_series_data.append({\n",
    "                        'timestamp': ts,\n",
    "                        'value': val,\n",
    "                        'group': group_label\n",
    "                    })\n",
    "\n",
    "            # Convert to DataFrame and sort by timestamp\n",
    "            ts_df = pd.DataFrame(all_time_series_data)\n",
    "            ts_df = ts_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "            # Convert to elapsed minutes from start\n",
    "            start_time = ts_df['timestamp'].min()\n",
    "            ts_df['elapsed_minutes'] = (ts_df['timestamp'] - start_time) / 60\n",
    "\n",
    "            # Plot the continuous time series with color coding by group\n",
    "            for idx, group_label in enumerate(group_labels):\n",
    "                group_segment = ts_df[ts_df['group'] == group_label]\n",
    "                if len(group_segment) > 0:\n",
    "                    color = colors[idx % len(colors)]\n",
    "                    ax.plot(group_segment['elapsed_minutes'], group_segment['value'],\n",
    "                        color=color, linewidth=1.5, alpha=0.8, label=group_label)\n",
    "                    ax.scatter(group_segment['elapsed_minutes'], group_segment['value'],\n",
    "                            color=color, s=8, alpha=0.6)\n",
    "\n",
    "            # Add vertical lines and labels to mark event boundaries\n",
    "            event_boundaries = []\n",
    "            for group_label in group_labels:\n",
    "                group_segment = ts_df[ts_df['group'] == group_label]\n",
    "                if len(group_segment) > 0:\n",
    "                    start_min = group_segment['elapsed_minutes'].min()\n",
    "                    end_min = group_segment['elapsed_minutes'].max()\n",
    "                    event_boundaries.append((group_label, start_min, end_min))\n",
    "\n",
    "            # Draw boundary lines and labels\n",
    "            y_min, y_max = ax.get_ylim()\n",
    "            for group_label, start_min, end_min in event_boundaries:\n",
    "                # Vertical lines at start and end\n",
    "                ax.axvline(x=start_min, color='black', linestyle='--', alpha=0.3, linewidth=1)\n",
    "                ax.axvline(x=end_min, color='black', linestyle='--', alpha=0.3, linewidth=1)\n",
    "                \n",
    "                # Label in the middle of the section\n",
    "                mid_min = (start_min + end_min) / 2\n",
    "                ax.text(mid_min, y_max * 0.97, group_label, \n",
    "                    ha='center', va='top', fontweight='bold', fontsize=10,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.4\", facecolor=\"white\", alpha=0.9, edgecolor='gray'))\n",
    "\n",
    "            # Format x-axis for elapsed time\n",
    "            max_minutes = ts_df['elapsed_minutes'].max()\n",
    "            if max_minutes <= 5:\n",
    "                tick_interval = 0.5\n",
    "            elif max_minutes <= 15:\n",
    "                tick_interval = 1\n",
    "            elif max_minutes <= 60:\n",
    "                tick_interval = 2\n",
    "            else:\n",
    "                tick_interval = 5\n",
    "\n",
    "            tick_positions = np.arange(0, max_minutes + tick_interval, tick_interval)\n",
    "            ax.set_xticks(tick_positions)\n",
    "            ax.set_xticklabels([f'{t:.1f}' if t % 1 != 0 else str(int(t)) for t in tick_positions])\n",
    "\n",
    "            ax.set_xlabel('Elapsed Time (minutes)', fontsize=12)\n",
    "            ax.set_ylabel(f'{metric} Value (bpm)', fontsize=12)\n",
    "            ax.set_title(f'{metric} Time Series: Chronological Progression', fontsize=14, fontweight='bold')\n",
    "            ax.legend(fontsize=10, loc='best')\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            plot2_path = os.path.join(OUTPUT_FOLDER, f'{metric}_timeseries.png')\n",
    "            plt.savefig(plot2_path, dpi=100, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            results['plots'].append({\n",
    "                'name': f'{metric} Time Series',\n",
    "                'path': plot2_path,\n",
    "                'filename': f'{metric}_timeseries.png',\n",
    "                'url': f'/api/plot/{metric}_timeseries.png'\n",
    "            })\n",
    "            print(f\"    ✓ Saved: {metric}_timeseries.png\")\n",
    "            \n",
    "            # Plot 3: Comparison summary (bar chart with stats)\n",
    "            fig, ax = plt.subplots(figsize=(max(10, len(group_data) * 2), 6))\n",
    "\n",
    "            group_labels = list(metric_results.keys())\n",
    "            means = [metric_results[label]['mean'] for label in group_labels]\n",
    "            stds = [metric_results[label]['std'] for label in group_labels]\n",
    "\n",
    "            x_pos = np.arange(len(group_labels))\n",
    "            bars = ax.bar(x_pos, means, yerr=stds, capsize=10, \n",
    "                        color=[colors[i % len(colors)] for i in range(len(group_labels))], \n",
    "                        alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "            ax.set_xticks(x_pos)\n",
    "            ax.set_xticklabels(group_labels, rotation=45, ha='right')\n",
    "            ax.set_ylabel(f'{metric} Value', fontsize=12)\n",
    "            ax.set_title(f'{metric}: Statistical Comparison', fontsize=14, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "\n",
    "            # Add value labels on bars\n",
    "            for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "                ax.text(i, mean + std + 0.05 * max(means), f'{mean:.2f}±{std:.2f}',\n",
    "                    ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plot3_path = os.path.join(OUTPUT_FOLDER, f'{metric}_comparison.png')\n",
    "            plt.savefig(plot3_path, dpi=100, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            results['plots'].append({\n",
    "                'name': f'{metric} Statistical Comparison',\n",
    "                'path': plot3_path,\n",
    "                'filename': f'{metric}_comparison.png',\n",
    "                'url': f'/api/plot/{metric}_comparison.png'\n",
    "            })\n",
    "            print(f\"    ✓ Saved: {metric}_comparison.png\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error analyzing {metric}: {str(e)}\"\n",
    "            print(f\"  ERROR: {error_msg}\")\n",
    "            results['errors'].append(error_msg)\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠ Skipping analysis - no event markers or metrics selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b040aba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:47:33.809700Z",
     "iopub.status.busy": "2025-10-15T18:47:33.809594Z",
     "iopub.status.idle": "2025-10-15T18:47:33.813547Z",
     "shell.execute_reply": "2025-10-15T18:47:33.813277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. SAVING RESULTS\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Analysis complete!\n",
      "  Status: completed\n",
      "  Plots generated: 3\n",
      "  Metrics analyzed: 1\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. SAVING RESULTS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "results['status'] = 'completed' if len(results['errors']) == 0 else 'completed_with_errors'\n",
    "results_path = os.path.join(OUTPUT_FOLDER, 'results.json')\n",
    "\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"✓ Analysis complete!\")\n",
    "print(f\"  Status: {results['status']}\")\n",
    "print(f\"  Plots generated: {len(results['plots'])}\")\n",
    "print(f\"  Metrics analyzed: {len(results.get('analysis', {}))}\")\n",
    "if results['errors']:\n",
    "    print(f\"  Errors: {len(results['errors'])}\")\n",
    "if results['warnings']:\n",
    "    print(f\"  Warnings: {len(results['warnings'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
